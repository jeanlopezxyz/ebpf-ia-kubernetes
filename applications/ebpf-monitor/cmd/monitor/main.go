package main

import (
	"bytes"
	"context"
	"encoding/binary"
	"encoding/json"
	"fmt"
	"log"
	"net"
	"net/http"
	"os"
	"os/signal"
	"strings"
	"sync"
	"syscall"
	"time"

	"github.com/cilium/ebpf/link"
	"github.com/cilium/ebpf/ringbuf"
	"github.com/cilium/ebpf/rlimit"
	"github.com/prometheus/client_golang/prometheus/promhttp"

	"github.com/jeanlopezxyz/ebpf-ia-gitops/applications/ebpf-monitor/pkg/config"
	"github.com/jeanlopezxyz/ebpf-ia-gitops/applications/ebpf-monitor/pkg/metrics"
)

//go:generate go run github.com/cilium/ebpf/cmd/bpf2go -cc clang -cflags "-O2 -g -Wall -Werror" network ../../bpf/network_monitor.c

// NetworkEvent represents a network event (must match C struct)
type NetworkEvent struct {
	SrcIP      uint32 `json:"src_ip"`
	DstIP      uint32 `json:"dst_ip"`
	SrcPort    uint16 `json:"src_port"`
	DstPort    uint16 `json:"dst_port"`
	Protocol   uint8  `json:"protocol"`
	PacketSize uint32 `json:"packet_size"`
	Timestamp  uint64 `json:"timestamp"`
	TCPFlags   uint8  `json:"tcp_flags"`
}

// NetworkStats holds aggregated statistics
type NetworkStats struct {
	PacketsPerSecond float64 `json:"packets_per_second"`
	BytesPerSecond   float64 `json:"bytes_per_second"`
	UniqueIPs        int     `json:"unique_ips"`
	UniquePorts      int     `json:"unique_ports"`
	TCPPackets       int64   `json:"tcp_packets"`
	UDPPackets       int64   `json:"udp_packets"`
	SYNPackets       int64   `json:"syn_packets"`
	
	// QoS metrics (Rakuten-style transport layer analysis)
	AvgLatencyMs     float64 `json:"avg_latency_ms"`
	MaxLatencyMs     float64 `json:"max_latency_ms"`  
	MinLatencyMs     float64 `json:"min_latency_ms"`
	JitterMs         float64 `json:"jitter_ms"`
	PacketLossRate   float64 `json:"packet_loss_rate"`
	RetransmitRate   float64 `json:"retransmit_rate"`
}

// Application represents the main eBPF application
type Application struct {
	config config.Config
	ctx    context.Context
	cancel context.CancelFunc

	// eBPF resources
	objs   *networkObjects
	link   link.Link
	reader *ringbuf.Reader

	// HTTP client for ML detector (reused)
	httpClient *http.Client

	// Statistics tracking
	mu         sync.RWMutex
	stats      NetworkStats
	ips        map[uint32]struct{}
	ports      map[uint16]struct{}
	ipCounts   map[uint32]int64  // Track packets per IP
	portCounts map[uint16]int64  // Track packets per port
	tcpPackets int64
	udpPackets int64
	synPackets int64
	totalBytes uint64
	totalPkts  uint64
	lastReset  time.Time
	
	// QoS tracking (Rakuten-style)
	latencies    []float64         // Latency samples in ms
	lastSeen     map[uint32]uint64 // Last seen timestamp per flow
	retransmits  int64            // TCP retransmission count
}

// NewApplication creates a new eBPF application
func NewApplication() (*Application, error) {
	cfg := config.New()
	metrics.Init()

	ctx, cancel := context.WithCancel(context.Background())

	return &Application{
		config:     cfg,
		ctx:        ctx,
		cancel:     cancel,
		httpClient: &http.Client{Timeout: cfg.HTTPClientTimeout},
		ips:        make(map[uint32]struct{}),
		ports:      make(map[uint16]struct{}),
		ipCounts:   make(map[uint32]int64),
		portCounts: make(map[uint16]int64),
		lastSeen:   make(map[uint32]uint64),
		latencies:  make([]float64, 0, 1000),
		lastReset:  time.Now(),
	}, nil
}

// setupEBPF loads and attaches the eBPF program
func (app *Application) setupEBPF() error {
	log.Printf("üîß Setting up eBPF program...")

	// Remove memory limit for eBPF
	if err := rlimit.RemoveMemlock(); err != nil {
		return fmt.Errorf("removing memlock: %w", err)
	}

	// Load eBPF objects (generated by bpf2go)
	app.objs = &networkObjects{}
	if err := loadNetworkObjects(app.objs, nil); err != nil {
		return fmt.Errorf("loading eBPF objects: %w", err)
	}

	// Find network interface
	iface, err := app.findInterface()
	if err != nil {
		return fmt.Errorf("finding interface: %w", err)
	}

	// Attach XDP program
	app.link, err = link.AttachXDP(link.XDPOptions{
		Program:   app.objs.NetworkMonitor,
		Interface: iface.Index,
	})
	if err != nil {
		return fmt.Errorf("attaching XDP to %s: %w", iface.Name, err)
	}

	// Create ring buffer reader
	app.reader, err = ringbuf.NewReader(app.objs.Events)
	if err != nil {
		return fmt.Errorf("creating ring buffer reader: %w", err)
	}

	log.Printf("‚úÖ eBPF program attached to interface %s", iface.Name)
	return nil
}

// findInterface finds a suitable network interface for eBPF
func (app *Application) findInterface() (*net.Interface, error) {
	// Try configured interface first
	if app.config.Interface != "" {
		if iface, err := net.InterfaceByName(app.config.Interface); err == nil {
			log.Printf("‚úÖ Using configured interface: %s", iface.Name)
			return iface, nil
		}
	}

	// Try common Kubernetes/container interfaces
	candidates := []string{"eth0", "cilium_host", "cni0", "docker0", "veth0", "lo"}

	for _, name := range candidates {
		if iface, err := net.InterfaceByName(name); err == nil && iface.Flags&net.FlagUp != 0 {
			log.Printf("‚úÖ Using interface: %s", name)
			return iface, nil
		}
	}

	return nil, fmt.Errorf("no suitable interface found (tried: %v)", candidates)
}

// startEventProcessor processes eBPF events from ring buffer
func (app *Application) startEventProcessor() {
	go func() {
		defer func() {
			if r := recover(); r != nil {
				log.Printf("‚ùå Event processor panic: %v", r)
				metrics.ProcessorErrorsTotal.Inc()
			}
		}()

		log.Printf("üîÑ Starting eBPF event processor...")

		for {
			select {
			case <-app.ctx.Done():
				log.Printf("üõë eBPF event processor stopping...")
				return
			default:
				// Read from ring buffer
				record, err := app.reader.Read()
				if err != nil {
					if app.isClosedError(err) {
						return
					}
					log.Printf("‚ö†Ô∏è  Ring buffer read error: %v", err)
					metrics.RingbufLostEventsTotal.Inc()
					time.Sleep(10 * time.Millisecond)
					continue
				}

				// Parse network event
				var event NetworkEvent
				if err := binary.Read(bytes.NewReader(record.RawSample), binary.LittleEndian, &event); err != nil {
					log.Printf("‚ö†Ô∏è  Event parse error: %v", err)
					metrics.ParseErrorsTotal.Inc()
					continue
				}

				// Process the event
				app.processEvent(event)
				metrics.EventsProcessedTotal.Inc()
			}
		}
	}()
}

// isClosedError checks if error indicates closed ring buffer
func (app *Application) isClosedError(err error) bool {
	errStr := err.Error()
	return strings.Contains(errStr, "closed") ||
		   strings.Contains(errStr, "EOF") ||
		   strings.Contains(errStr, "context canceled")
}

// ipToString converts IP from uint32 to string
func ipToString(ip uint32) string {
	return fmt.Sprintf("%d.%d.%d.%d",
		byte(ip), byte(ip>>8), byte(ip>>16), byte(ip>>24))
}

// processEvent processes a network event
func (app *Application) processEvent(event NetworkEvent) {
	app.mu.Lock()
	defer app.mu.Unlock()

	// Update counters
	switch event.Protocol {
	case 6: // TCP
		app.tcpPackets++
		if event.TCPFlags&0x02 != 0 { // SYN flag
			app.synPackets++
			metrics.SynPacketsTotal.Inc()
		}
		metrics.PacketsProcessed.WithLabelValues("tcp", "inbound").Inc()
	case 17: // UDP
		app.udpPackets++
		metrics.PacketsProcessed.WithLabelValues("udp", "inbound").Inc()
	default:
		metrics.PacketsProcessed.WithLabelValues("other", "inbound").Inc()
	}

	metrics.BytesProcessed.WithLabelValues(protocolName(event.Protocol)).Add(float64(event.PacketSize))

	// Track unique IPs and ports with counts
	app.ips[event.SrcIP] = struct{}{}
	app.ips[event.DstIP] = struct{}{}
	app.ipCounts[event.SrcIP]++
	app.ipCounts[event.DstIP]++
	
	if event.SrcPort != 0 {
		app.ports[event.SrcPort] = struct{}{}
		app.portCounts[event.SrcPort]++
	}
	if event.DstPort != 0 {
		app.ports[event.DstPort] = struct{}{}
		app.portCounts[event.DstPort]++
	}

	app.totalBytes += uint64(event.PacketSize)
	app.totalPkts++
	
	// QoS analysis (Rakuten-style transport layer)
	flowKey := event.SrcIP ^ event.DstIP  // Simple flow identifier
	currentTime := event.Timestamp
	
	if lastTime, exists := app.lastSeen[flowKey]; exists {
		// Calculate latency between packets in same flow
		latencyNs := currentTime - lastTime
		latencyMs := float64(latencyNs) / 1000000.0  // Convert to ms
		
		if latencyMs > 0 && latencyMs < 1000 {  // Reasonable latency range
			app.latencies = append(app.latencies, latencyMs)
			
			// Keep latency buffer reasonable size
			if len(app.latencies) > 1000 {
				app.latencies = app.latencies[500:]  // Keep last 500
			}
		}
	}
	app.lastSeen[flowKey] = currentTime
	
	// Detect retransmissions (simplified)
	if event.Protocol == 6 && event.TCPFlags&0x08 != 0 {  // TCP with retransmit flag approximation
		app.retransmits++
	}

	// Log interesting packets
	if event.SrcPort != 0 || event.DstPort != 0 {
		log.Printf("üåê eBPF CAPTURED: %s:%d -> %s:%d [%s] %d bytes flags:0x%02x",
			ipToString(event.SrcIP), event.SrcPort,
			ipToString(event.DstIP), event.DstPort,
			protocolName(event.Protocol), event.PacketSize, event.TCPFlags)
	}
}

// protocolName converts protocol number to string
func protocolName(proto uint8) string {
	switch proto {
	case 6:
		return "tcp"
	case 17:
		return "udp"
	case 1:
		return "icmp"
	default:
		return "other"
	}
}

// updateStats periodically updates statistics
func (app *Application) updateStats() {
	ticker := time.NewTicker(app.config.StatsWindow)
	defer ticker.Stop()

	for {
		select {
		case <-app.ctx.Done():
			return
		case <-ticker.C:
			app.mu.Lock()
			elapsed := time.Since(app.lastReset).Seconds()
			if elapsed > 0.001 { // Minimum 1ms to avoid inflated rates
				app.stats.PacketsPerSecond = float64(app.totalPkts) / elapsed
				app.stats.BytesPerSecond = float64(app.totalBytes) / elapsed
				app.stats.UniqueIPs = len(app.ips)
				app.stats.UniquePorts = len(app.ports)
				app.stats.TCPPackets = app.tcpPackets
				app.stats.UDPPackets = app.udpPackets
				app.stats.SYNPackets = app.synPackets
				
				// Calculate QoS statistics (Rakuten-style)
				if len(app.latencies) > 0 {
					app.stats.AvgLatencyMs = calculateMean(app.latencies)
					app.stats.MaxLatencyMs = calculateMax(app.latencies)
					app.stats.MinLatencyMs = calculateMin(app.latencies)
					app.stats.JitterMs = calculateJitter(app.latencies)
				}
				
				// Calculate packet loss and retransmission rates
				if app.totalPkts > 0 {
					app.stats.RetransmitRate = float64(app.retransmits) / float64(app.totalPkts)
					// Simplified packet loss estimation
					app.stats.PacketLossRate = app.stats.RetransmitRate * 0.5  // Approximation
				}

				// Update Prometheus gauges
				metrics.PacketsPerSecond.Set(app.stats.PacketsPerSecond)
				metrics.BytesPerSecond.Set(app.stats.BytesPerSecond)
				metrics.UniqueIPs.Set(float64(app.stats.UniqueIPs))
				metrics.UniquePorts.Set(float64(app.stats.UniquePorts))

				// Reset for next window
				app.ips = make(map[uint32]struct{})
				app.ports = make(map[uint16]struct{})
				app.ipCounts = make(map[uint32]int64)
				app.portCounts = make(map[uint16]int64)
				app.tcpPackets = 0
				app.udpPackets = 0
				app.synPackets = 0
				app.totalBytes = 0
				app.totalPkts = 0
				app.lastReset = time.Now()
			}
			app.mu.Unlock()
		}
	}
}

// getStats returns current statistics
func (app *Application) getStats() NetworkStats {
	app.mu.RLock()
	defer app.mu.RUnlock()
	return app.stats
}

// getTopIPs returns top N IPs by packet count
func (app *Application) getTopIPs(n int) map[string]int64 {
	app.mu.RLock()
	defer app.mu.RUnlock()
	
	type ipCount struct {
		ip    string
		count int64
	}
	
	var ips []ipCount
	for ip, count := range app.ipCounts {
		ips = append(ips, ipCount{ipToString(ip), count})
	}
	
	// Simple sort - get top N
	result := make(map[string]int64)
	for i := 0; i < len(ips) && i < n; i++ {
		maxIdx := i
		for j := i + 1; j < len(ips); j++ {
			if ips[j].count > ips[maxIdx].count {
				maxIdx = j
			}
		}
		if maxIdx != i {
			ips[i], ips[maxIdx] = ips[maxIdx], ips[i]
		}
		result[ips[i].ip] = ips[i].count
	}
	return result
}

// QoS calculation functions (Rakuten-style)
func calculateMean(values []float64) float64 {
	if len(values) == 0 {
		return 0
	}
	sum := 0.0
	for _, v := range values {
		sum += v
	}
	return sum / float64(len(values))
}

func calculateMax(values []float64) float64 {
	if len(values) == 0 {
		return 0
	}
	max := values[0]
	for _, v := range values {
		if v > max {
			max = v
		}
	}
	return max
}

func calculateMin(values []float64) float64 {
	if len(values) == 0 {
		return 0
	}
	min := values[0]
	for _, v := range values {
		if v < min {
			min = v
		}
	}
	return min
}

func calculateJitter(values []float64) float64 {
	if len(values) < 2 {
		return 0
	}
	
	// Calculate variance in latency (simplified jitter)
	mean := calculateMean(values)
	sumSquares := 0.0
	for _, v := range values {
		diff := v - mean
		sumSquares += diff * diff
	}
	variance := sumSquares / float64(len(values))
	return variance  // Simplified jitter as variance
}

// startHTTPServer starts the HTTP API server
func (app *Application) startHTTPServer() error {
	mux := http.NewServeMux()

	// Health check
	mux.HandleFunc("/health", func(w http.ResponseWriter, r *http.Request) {
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(map[string]interface{}{
			"status":    "healthy",
			"service":   "ebpf-monitor",
			"version":   "3.0.0",
			"mode":      "eBPF_real_traffic",
			"timestamp": time.Now().Format(time.RFC3339),
		})
	})

	// Statistics
	mux.HandleFunc("/stats", func(w http.ResponseWriter, r *http.Request) {
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(app.getStats())
	})

	// Root info
	mux.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(map[string]interface{}{
			"service":     "eBPF Network Monitor",
			"version":     "3.0.0",
			"description": "Real-time network monitoring using eBPF + AI threat detection",
			"endpoints": []string{"/health", "/stats", "/metrics"},
		})
	})

	// Prometheus metrics
	mux.Handle("/metrics", promhttp.Handler())

	log.Printf("üåê HTTP server starting on %s", app.config.HTTPAddr)

	server := &http.Server{
		Addr:         app.config.HTTPAddr,
		Handler:      mux,
		ReadTimeout:  app.config.ReadTimeout,
		WriteTimeout: app.config.WriteTimeout,
		IdleTimeout:  app.config.IdleTimeout,
	}

	go func() {
		<-app.ctx.Done()
		log.Printf("üõë HTTP server shutting down...")
		ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
		defer cancel()
		server.Shutdown(ctx)
	}()

	return server.ListenAndServe()
}

// startMLClient sends data to ML Detector
func (app *Application) startMLClient() {
	log.Printf("ü§ñ ML client starting -> %s (every %v)", app.config.MLDetectorURL, app.config.PostInterval)

	go func() {
		ticker := time.NewTicker(app.config.PostInterval)
		defer ticker.Stop()

		for {
			select {
			case <-app.ctx.Done():
				log.Printf("üõë ML client stopping...")
				return
			case <-ticker.C:
				stats := app.getStats()
				topIPs := app.getTopIPs(10) // Get top 10 IPs

				features := map[string]interface{}{
					"packets_per_second": stats.PacketsPerSecond,
					"bytes_per_second":   stats.BytesPerSecond,
					"unique_ips":         stats.UniqueIPs,
					"unique_ports":       stats.UniquePorts,
					"tcp_packets":        stats.TCPPackets,
					"udp_packets":        stats.UDPPackets,
					"syn_packets":        stats.SYNPackets,
					"top_ips":           topIPs, // Include specific attacking IPs
					
					// QoS metrics (Rakuten-style transport analysis)
					"avg_latency_ms":    stats.AvgLatencyMs,
					"max_latency_ms":    stats.MaxLatencyMs,
					"jitter_ms":         stats.JitterMs,
					"packet_loss_rate":  stats.PacketLossRate,
					"retransmit_rate":   stats.RetransmitRate,
				}

				log.Printf("üìä Sending to ML: pps=%.2f, bps=%.2f, ips=%d, ports=%d",
					stats.PacketsPerSecond, stats.BytesPerSecond, stats.UniqueIPs, stats.UniquePorts)

				if err := app.sendToMLDetector(features); err != nil {
					log.Printf("‚ö†Ô∏è  ML Detector error: %v", err)
					metrics.MLPostFailuresTotal.Inc()
				} else {
					log.Printf("‚úÖ ML Detector: data sent successfully")
				}
			}
		}
	}()
}

// sendToMLDetector sends features to ML Detector
func (app *Application) sendToMLDetector(features map[string]interface{}) error {
	jsonData, err := json.Marshal(features)
	if err != nil {
		return fmt.Errorf("marshaling: %w", err)
	}

	resp, err := app.httpClient.Post(
		app.config.MLDetectorURL+"/detect",
		"application/json",
		bytes.NewBuffer(jsonData),
	)
	if err != nil {
		return fmt.Errorf("HTTP post: %w", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode >= 400 {
		return fmt.Errorf("ML detector status: %d", resp.StatusCode)
	}

	// eBPF Monitor only sends data - ML Detector handles threat detection
	return nil
}

// cleanup releases eBPF resources
func (app *Application) cleanup() {
	log.Printf("üßπ Cleaning up eBPF resources...")

	app.cancel()

	if app.reader != nil {
		app.reader.Close()
	}

	if app.link != nil {
		app.link.Close()
	}

	if app.objs != nil {
		app.objs.Close()
	}

	log.Printf("‚úÖ eBPF cleanup completed")
}

// Run starts the eBPF application
func (app *Application) Run() error {
	log.Printf("üöÄ Starting eBPF Network Monitor v3.0.0")
	log.Printf("üìä Interface: %s, HTTP: %s, ML: %s",
		app.config.Interface, app.config.HTTPAddr, app.config.MLDetectorURL)

	// Setup eBPF program
	if err := app.setupEBPF(); err != nil {
		return fmt.Errorf("eBPF setup failed: %w", err)
	}

	// Start statistics updater
	go app.updateStats()

	// Start eBPF event processor
	app.startEventProcessor()

	// Start ML client
	go app.startMLClient()

	// Start HTTP server
	go func() {
		if err := app.startHTTPServer(); err != nil && err != http.ErrServerClosed {
			log.Printf("‚ùå HTTP server error: %v", err)
		}
	}()

	log.Printf("‚úÖ eBPF Network Monitor ready - capturing REAL network traffic!")

	// Wait for shutdown
	sigChan := make(chan os.Signal, 1)
	signal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)

	<-sigChan
	log.Printf("üõë Shutdown signal received")

	app.cleanup()
	return nil
}

func main() {
	log.SetFlags(log.LstdFlags | log.Lshortfile)

	app, err := NewApplication()
	if err != nil {
		log.Fatalf("‚ùå Application creation failed: %v", err)
	}

	if err := app.Run(); err != nil {
		log.Fatalf("‚ùå eBPF application failed: %v", err)
	}
}